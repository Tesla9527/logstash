[[persistent-queues]]
=== Persistent Queues

WARNING: This functionality is in beta and is subject to change. Deployment in production is at your own risk.

By default, Logstash uses in-memory bounded queues between pipeline stages
(inputs → pipeline workers) to buffer events. The size of these in-memory
queues is fixed and not configurable. If Logstash terminates abnormally,
either as the result of a software crash or `kill -9`, it's
possible to lose queued events. 

To prevent event loss in these scenarios, you can configure Logstash to use
persistent queues. With persistent queues enabled, Logstash stores 
the queue on disk.

Persistent queues are also useful for Logstash deployments that require high
throughput and resiliency. Instead of deploying and managing a message
broker, such as Redis, RabbitMQ, or Apache Kafka, to handle a mismatch in
cadence between the shipping stage and the relatively expensive processing
stage, you can enable persistent queues to buffer events on disk. The persistent queue has configurable sizing, which means that you have more control over
managing situations that can result in back pressure to the source. See <<backpressure-persistent-queues>>. 

[[persistent-queues-advantages]]
==== Advantages of Persistent Queues

Using persistent queues:

* Provides protection from losing in-flight messages when the Logstash process is abnormally terminated.
* Absorb bursts of events without needing an external queueing mechanism like Redis or Kafka.
* Depending on configuration, can provide an at-least-once message
delivery guarantee. If Logstash is restarted while events are in-flight,
Logstash will attempt to deliver messages stored in the persistent queue until
delivery succeeds at least once. In other words, messages stored in the
persistent queue may be duplicated, but not lost.

[[persistent-queues-limitations]]
==== Limitations of Persistent Queues

Persistent queues solves many problems, but the following are problems not
solved:

* Inputs which do not use a request-response protocol cannot be protected from data loss. For example: tcp, udp, zeromq push+pull, and many other inputs do not have a mechanism to acknowledge receipt to the sender. Plugins such as beats and http, which *do* have a acknowledgement capability, are well protected by this queue.
* It does not handle permanent disk or machine failures. The data persisted to disk is not replicated, so it is still a single point of failure.

[[persistent-queues-architecture]]
==== How Persistent Queues Work

The persistent queue sits between the input and filter stages in the same
process:

input → persistent queue → filter + output 

The input stage reads data from the configured data source and writes events to
the persistent queue for processing. Logstash reads a batch of events from the
persistent queue and sends them to the filter and output stages. As events
are processed, Logstash records a checkpoint to track which events are
successfully acknowledged (ACKed) as processed by Logstash. An event is
recorded as ACKed in the checkpoint if the event is successfully sent to the
last output stage in the pipeline;

During a normal, controlled shutdown (*CTRL+C* or SIGTERM), Logstash finishes
processing the current in-flight events (that is, the events being processed by
the filter and output stages, not the queued events), finalizes the ACKing
of these events, and then terminates the Logstash process. Upon restart,
Logstash uses last checkpoint to resume processing the events in the backlog. 

If Logstash crashes or experiences an uncontrolled shutdown, any in-flight
events are left as unACKed in the persistent queue; during these abnormal
terminations, Logstash is unable to safely save a new checkpoint, so the most
recent checkpoint will be used on startup. Logstash will again resume from the
last checkpoint the events from its history. This scenario can lead to some
recent events being processed twice (once before the crash, and once upon
restart and resuming).

[[configuring-persistent-queues]]
==== Configuring Persistent Queues

To configure persistent queues, you can specify the following options in the
Logstash <<logstash-settings-file,settings file>>:

* `queue.type`: Specify `persisted` to enable persistent queues. By default, persistent queues are disabled (default: `queue.type: memory`).
* `path.queue`: The directory path where the data files will be stored. By default, the files are stored in `path.data/queue`. 
* `queue.page_capacity`: The size of the page data file. The queue data consists of append-only data files separated into pages. The default size is 250mb. 
* `queue.max_events`:  The maximum number of unACKed events that are allowed in the queue. The default is 0 (unlimited).
* `queue.max_bytes`: The total capacity of the queue in number of bytes. The
default is 1024mb (1gb). Make sure the capacity of your disk drive is greater
than the value you specify here.

If both `queue.max_events` and 
`queue.max_bytes` are specified, Logstash uses whichever criteria is reached
first. See <<backpressure-persistent-queue>> for behavior when these queue limits are reached.

You can also specify options that control when the checkpoint file gets updated (`queue.checkpoint.acks`, `queue.checkpoint.writes`). See <<durability-persistent-queues>>.

Example configuration:

[source, yaml]
queue.type: persisted
queue.max_bytes: 4gb 

[[backpressure-persistent-queues]]
==== Handling Back Pressure

Logstash has a built-in mechanism that exerts back pressure on the data flow 
when the queue is full. This mechanism helps Logstash control the rate of data
flow at the input stage without overwhelming downstream stages and outputs like
Elasticsearch.

You can control when back pressure happens by using the `queue.max_bytes` 
setting to configure the capacity of the queue on disk. The following example
sets the total capacity of the queue to 8gb:

[source, yaml]
queue.type: persisted
queue.max_bytes: 8gb

With these settings specified, Logstash will buffer unACKed events on disk until 
the size of the queue reaches 8gb. When the queue is full of unACKed events, and
the size limit has been reached, Logstash will no longer accept new events. 

Each input handles back pressure independently. For example, when the
<<plugins-inputs-beats,beats>> input encounters back pressure, it no longer
accepts new connections and waits until the persistent queue has space to accept
more events. After the filter and output stages finish processing existing
events in the queue and ACKs them, Logstash automatically starts accepting new
events.

[[durability-persistent-queues]]
==== Controlling Durability

When the persistent queue feature is enabled, Logstash will store events on
disk. The persistent queue exposes the trade-off between performance and
durability by providing the following configuration options:

* `queue.checkpoint.writes`: The number of writes to the queue to trigger an
fsync to disk. This configuration controls the durability from the producer
side. Keep in mind that a disk flush is a relatively heavy operation that will
affect throughput if performed after every write. For instance, if you want to
ensure that all messages in Logstash's queue are durable, you can set
`queue.checkpoint.writes: 1`. However, this setting can severely impact
performance.

* `queue.checkpoint.acks`: The number of ACKs to the queue to trigger an fsync to disk. This configuration controls the durability from the consumer side.

The process of checkpointing is atomic, which means any update to the file is
saved if successful.

If Logstash is terminated, or if there is a hardware level failure, any data
that is buffered in the persistent queue, but not yet checkpointed, is lost.
To avoid this possibility, you can set `queue.checkpoint.writes: 1`, but keep in
mind that this setting can severely impact performance.
